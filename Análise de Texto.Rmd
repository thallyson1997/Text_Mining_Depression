---
title: "Análise de Texto - Preparando os Dados"
output: html_notebook
---
# Carregando os pacotes
```{r}
library(stringr)
library(tm)
library(caret)
library(pROC)
library(randomForest)
library(xgboost)
library(smotefamily)
library(glmnet)
```
# Carregando os dados de treinamento e teste
```{r}
# Crie listas vazias para TREINO e TESTE
TREINO <- list()
TESTE <- list()

# Loop para carregar os conjuntos de dados
for (i in 1:10) {
  arquivo_treino <- paste0("C:\\Users\\usuario\\OneDrive\\Documentos\\Text_Mining_Reddit_Depression_Post\\Dados\\treino_", i, ".csv")
  arquivo_teste <- paste0("C:\\Users\\usuario\\OneDrive\\Documentos\\Text_Mining_Reddit_Depression_Post\\Dados\\teste_", i, ".csv")
  conjunto_dados_treino <- read.csv(arquivo_treino, row.names = NULL)
  conjunto_dados_teste <- read.csv(arquivo_teste, row.names = NULL)
  conjunto_dados_treino <- subset(conjunto_dados_treino, select = -c(X))
  conjunto_dados_teste <- subset(conjunto_dados_teste, select = -c(X))
  TREINO[[i]] <- conjunto_dados_treino
  TESTE[[i]] <- conjunto_dados_teste
}
```
# Preparando os dados
```{r}
# Função remover_regex para remover expressões regulares.
remover_regex <- function(texto){
  lista <- c("<INDIVIDUAL>\n", "</INDIVIDUAL>\n", 
             "<WRITING>\n\t", "</WRITING>\n", 
             "<TITLE>", "</TITLE>\n\t", 
             "<TEXT>", "</TEXT>\n",
             "<ID>.*</ID>\n", "<DATE>.*</DATE>\n\t", 
             "<INFO>.*</INFO>\n\t", "    ", "  ", "\n")
  for (i in lista){
    texto <- str_replace_all(texto, i, "")
  }
  return(texto)
}
# Função remover_ruido para remover pontuações, números, urls.
remover_ruido <- function(texto){
  texto <-  gsub('[[:punct:] ]+', ' ', texto)
  texto <- gsub('[[:digit:]]+', '', texto)
  return(texto)
}
# Função remover_stopwords para remover palavras comuns da lingua inglesa
remover_stopword <- function(texto){
  stopwords <- c('i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', "you're", "you've", "you'll", "you'd", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', "she's", 'her', 'hers', 'herself', 'it', "it's", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', "that'll", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', "don't", 'should', "should've", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', "aren't", 'couldn', "couldn't", 'didn', "didn't", 'doesn', "doesn't", 'hadn', "hadn't", 'hasn', "hasn't", 'haven', "haven't", 'isn', "isn't", 'ma', 'mightn', "mightn't", 'mustn', "mustn't", 'needn', "needn't", 'shan', "shan't", 'shouldn', "shouldn't", 'wasn', "wasn't", 'weren', "weren't", 'won', "won't", 'wouldn', "wouldn't")
  texto <- removeWords(texto, stopwords)
  return(texto)
}

# Função preprocessamento contem todas as função que preparam o dataset
preprocessamento <- function(dataset){
  dataset$Postagens <- lapply(dataset$Postagens, remover_regex)
  dataset$Postagens <- lapply(dataset$Postagens, remover_ruido)
  dataset$Postagens <- lapply(dataset$Postagens, tolower)
  dataset$Postagens <- lapply(dataset$Postagens, remover_stopword)
  dataset$Postagens <- lapply(dataset$Postagens, stemDocument)
  return(dataset)
}

# Preparando os dados de treinamento e teste
TREINO <- lapply(TREINO, preprocessamento)
TESTE <- lapply(TESTE, preprocessamento)
```
# Salvar dataset preparados
```{r}
# Criar pasta para salvar arquivos preparados
dir_saida <- "C:/Users/usuario/OneDrive/Documentos/Text_Mining_Reddit_Depression_Post/Dados_Preparados"
dir.create(dir_saida, showWarnings = FALSE)

# Função para salvar datasets em CSV
salvar_datasets <- function(lista, prefixo, pasta){
  for (i in seq_along(lista)){
    df <- lista[[i]]
    
    # Garantir que a coluna Postagens é character, não lista
    if ("Postagens" %in% names(df)) {
      df$Postagens <- as.character(df$Postagens)
    }
    
    caminho <- file.path(pasta, paste0(prefixo, "_", i, "_preparado.csv"))
    write.csv(df, caminho, row.names = FALSE)
  }
}

# Salvar os conjuntos de treino e teste
salvar_datasets(TREINO, "treino", dir_saida)
salvar_datasets(TESTE, "teste", dir_saida)
```
# üìå Reposit√≥rio: Minera√ß√£o de Texto para Predi√ß√£o de Depress√£o

Este reposit√≥rio cont√©m os c√≥digos, dados preparados e resultados de experimentos de **minera√ß√£o de texto** aplicados ao problema de **predi√ß√£o de depress√£o em postagens do Reddit**.

## üìÇ Estrutura do Reposit√≥rio

* `Dados/` (**ignorado no Git**): cont√©m os dados originais e sens√≠veis, n√£o disponibilizados publicamente.
* `Dados_Preparados/`: cont√©m os dados tratados e prontos para uso nos modelos.
* `Resultado/`: cont√©m as m√©tricas, predi√ß√µes e gr√°ficos gerados durante os experimentos.
* Notebooks R (`.Rmd`): c√≥digo de prepara√ß√£o, modelagem e an√°lise.

## üîπ Etapa 1 - Prepara√ß√£o dos Dados (`An√°lise de Texto.Rmd`)

O notebook **An√°lise de Texto.Rmd** realiza o **pr√©-processamento textual** das postagens de usu√°rios divididas em 10 segmentos temporais (treino e teste).

### üì• Carregamento dos Dados

* Os dados originais (`treino_1.csv` ‚Ä¶ `treino_10.csv`, `teste_1.csv` ‚Ä¶ `teste_10.csv`) s√£o lidos da pasta `Dados/`.
* Cada conjunto √© armazenado em listas (`TREINO` e `TESTE`).

### üßπ Pr√©-processamento aplicado

O texto passa por v√°rias etapas de limpeza:

1. **Remo√ß√£o de marca√ß√µes XML**: usando a fun√ß√£o `remover_regex`.
2. **Remo√ß√£o de ru√≠dos**: n√∫meros, pontua√ß√µes e URLs (`remover_ruido`).
3. **Normaliza√ß√£o**: convers√£o para min√∫sculas.
4. **Stopwords**: remo√ß√£o de palavras comuns da l√≠ngua inglesa (`remover_stopword`).
5. **Stemming**: redu√ß√£o de palavras ao seu radical (`stemDocument`).

Todas essas fun√ß√µes s√£o aplicadas dentro da fun√ß√£o principal `preprocessamento()`.

### üíæ Salvamento dos Dados Preparados

* Ap√≥s o pr√©-processamento, os conjuntos s√£o salvos em **`Dados_Preparados/`** nos arquivos:

  * `treino_1_preparado.csv` ‚Ä¶ `treino_10_preparado.csv`
  * `teste_1_preparado.csv` ‚Ä¶ `teste_10_preparado.csv`
* Essa etapa garante que os dados tratados fiquem dispon√≠veis publicamente para reprodutibilidade, sem expor informa√ß√µes sens√≠veis.

## üîπ Etapa 2 - M√©todo 1: Sem Altera√ß√£o (`Metodo_01.Rmd`)

O **M√©todo 1** aplica diretamente o processo de modelagem aos dados preparados, sem nenhuma modifica√ß√£o adicional al√©m da vetoriza√ß√£o e treinamento.

### ‚öôÔ∏è Pipeline do M√©todo 1

1. **Carregamento dos dados preparados**

   * Os arquivos `treino_X_preparado.csv` e `teste_X_preparado.csv` s√£o carregados da pasta `Dados_Preparados/`.
   * Os conjuntos s√£o armazenados em listas (`TREINO` e `TESTE`) para os 10 segmentos temporais.

2. **Vetoriza√ß√£o com TF-IDF**

   * Cada fold de treino e teste √© transformado em matrizes TF-IDF.
   * S√£o selecionadas as **250 palavras mais relevantes** (com maior soma de pesos TF-IDF).
   * Apenas colunas em comum entre treino e teste s√£o mantidas.

3. **Treinamento e Avalia√ß√£o**

   * Tr√™s modelos foram testados com diferentes hiperpar√¢metros:

     * **Random Forest (RF)** ‚Üí `mtry = {2, 126, 250}`
     * **XGBoost (XGB)** ‚Üí `nrounds = {250, 300, 350}`
     * **Regress√£o Log√≠stica Regularizada (GLMNET)** ‚Üí `lambda = {0.1, 0.5, 1}`
   * O treinamento √© feito via `caret::train()` com **valida√ß√£o cruzada interna**.

4. **M√©tricas de Avalia√ß√£o**
   Para cada modelo, par√¢metro e fold, s√£o calculadas:

   * **Acur√°cia**
   * **Recall (Sensibilidade)**
   * **Especificidade**
   * **F1-score**
   * **AUC-ROC**

5. **Sa√≠das Geradas**

   * **Predi√ß√µes por fold**: arquivos `_predicoes.csv` com colunas:

     * `Usuario`, `Classe` (real), `Predito_1 ‚Ä¶ Predito_10` (resultado por fold).
   * **M√©tricas individuais**: arquivos `_metricas_long.csv` contendo os valores de m√©tricas por fold.
   * **M√©tricas m√©dias**: arquivo `metricas_medias.csv` com a m√©dia de cada m√©trica para cada modelo/par√¢metro.
   * **Matrizes de confus√£o** (por usu√°rio, com predi√ß√£o agregada por maioria de folds):

     * Arquivos `.csv` e imagens `.png` para auditoria.
   * **Boxplots comparativos**: cinco gr√°ficos (um para cada m√©trica) comparando os modelos e par√¢metros.

### üìä Sa√≠da da pasta `Resultado/METODO_1`

* `*_predicoes.csv` ‚Üí predi√ß√µes por usu√°rio/fold.
* `*_metricas_long.csv` ‚Üí m√©tricas detalhadas por fold.
* `metricas_medias.csv` ‚Üí resumo comparativo de desempenho.
* `*_confusion_matrix.csv` e `*_confusion_matrix.png` ‚Üí matrizes de confus√£o agregadas.
* `Boxplot_Acuracia.png`, `Boxplot_Recall.png`, ‚Ä¶ ‚Üí gr√°ficos comparativos.

## üîπ Etapa 3 - M√©todo 2: Redu√ß√£o da Classe Majorit√°ria (`Metodo_02.Rmd`)

O **M√©todo 2** introduz uma t√©cnica de balanceamento antes da vetoriza√ß√£o: a **redu√ß√£o da classe majorit√°ria**.
Assim, o n√∫mero de inst√¢ncias da classe negativa (`0`) √© reduzido at√© igualar o da classe positiva (`1`).

### ‚öôÔ∏è Pipeline do M√©todo 2

1. **Carregamento dos dados preparados**

   * Utiliza os arquivos da pasta `Dados_Preparados/`, carregando-os em listas (`TREINO`, `TESTE`).

2. **Balanceamento das classes**

   * Para cada fold de treino:

     * Calcula o tamanho dos textos.
     * Ordena os exemplos por tamanho decrescente.
     * Mant√©m **todos os exemplos da classe `1`**.
     * Seleciona a mesma quantidade de exemplos da classe `0` (reduzindo o excesso).
   * O dataset resultante √© balanceado (`n0 = n1`).

3. **Vetoriza√ß√£o com TF-IDF**

   * Como no M√©todo 1, os textos s√£o transformados em representa√ß√µes TF-IDF.
   * Sele√ß√£o das **250 palavras mais relevantes**.
   * Apenas colunas em comum entre treino e teste s√£o mantidas.

4. **Treinamento e Avalia√ß√£o**

   * Modelos utilizados e par√¢metros:

     * **Random Forest (RF)** ‚Üí `mtry = {2, 126, 250}`
     * **XGBoost (XGB)** ‚Üí `nrounds = {250, 300, 350}`
     * **Regress√£o Log√≠stica Regularizada (GLMNET)** ‚Üí `lambda = {0.1, 0.5, 1}`
   * Avalia√ß√£o com valida√ß√£o cruzada e m√©tricas padr√£o.

5. **M√©tricas calculadas**

   * **Acur√°cia**
   * **Recall (Sensibilidade)**
   * **Especificidade**
   * **F1-score**
   * **AUC-ROC**

6. **Sa√≠das geradas**

   * **Predi√ß√µes por usu√°rio/fold**: arquivos `_predicoes.csv`.
   * **M√©tricas individuais**: `_metricas_long.csv`.
   * **Matrizes de confus√£o**: agregadas por usu√°rio (maioria de folds).

     * Arquivos `.csv` e imagens `.png`.
   * **M√©tricas m√©dias**: `metricas_medias.csv`.
   * **Boxplots comparativos**: gr√°ficos para cada m√©trica, comparando modelos e par√¢metros.

### üìä Sa√≠da da pasta `Resultado/METODO_2`

* `*_predicoes.csv` ‚Üí predi√ß√µes por usu√°rio/fold.
* `*_metricas_long.csv` ‚Üí m√©tricas detalhadas por fold.
* `metricas_medias.csv` ‚Üí resumo comparativo de desempenho.
* `*_confusion_matrix.csv` e `*_confusion_matrix.png` ‚Üí matrizes de confus√£o agregadas.
* `Boxplot_Acuracia.png`, `Boxplot_Recall.png`, ‚Ä¶ ‚Üí gr√°ficos comparativos.

## üîπ Etapa 4 - M√©todo 3: Redu√ß√£o Parcial da Classe Majorit√°ria (`Metodo_03.Rmd`)

O **M√©todo 3** adota uma estrat√©gia de **redu√ß√£o parcial da classe majorit√°ria**, em que a quantidade de exemplos negativos (`0`) √© **limitada a aproximadamente 2,5 vezes** a quantidade de exemplos positivos (`1`).
Dessa forma, busca-se **diminuir o desbalanceamento** sem eliminar totalmente a predomin√¢ncia da classe negativa.

### ‚öôÔ∏è Pipeline do M√©todo 3

1. **Carregamento dos dados preparados**

   * Carregamento dos arquivos da pasta `Dados_Preparados/` em listas (`TREINO`, `TESTE`).

2. **Balanceamento parcial das classes**

   * Para cada fold de treino:

     * Ordena os textos pelo tamanho (n√∫mero de caracteres).
     * Mant√©m **todos os exemplos da classe `1`**.
     * Seleciona uma quantidade de exemplos da classe `0` **igual a 2,5 vezes o n√∫mero da classe `1`**.
   * O dataset resultante reduz parcialmente a classe majorit√°ria (`2.5 * n1 ‚âà n0`).

3. **Vetoriza√ß√£o com TF-IDF**

   * Transforma√ß√£o das postagens em representa√ß√µes TF-IDF.
   * Sele√ß√£o das **250 palavras mais relevantes**.
   * Apenas colunas em comum entre treino e teste s√£o utilizadas.

4. **Treinamento e Avalia√ß√£o**

   * Modelos e par√¢metros avaliados:

     * **Random Forest (RF)** ‚Üí `mtry = {2, 126, 250}`
     * **XGBoost (XGB)** ‚Üí `nrounds = {250, 300, 350}`
     * **Regress√£o Log√≠stica Regularizada (GLMNET)** ‚Üí `lambda = {0.1, 0.5, 1}`
   * Valida√ß√£o cruzada com m√©tricas detalhadas.

5. **M√©tricas calculadas**

   * **Acur√°cia**
   * **Recall (Sensibilidade)**
   * **Especificidade**
   * **F1-score**
   * **AUC-ROC**

6. **Sa√≠das geradas**

   * **Predi√ß√µes por usu√°rio/fold**: arquivos `_predicoes.csv`.
   * **M√©tricas individuais**: `_metricas_long.csv`.
   * **Matrizes de confus√£o**: agregadas por usu√°rio (maioria dos folds).

     * Arquivos `.csv` e imagens `.png`.
   * **M√©tricas m√©dias**: `metricas_medias.csv`.
   * **Boxplots comparativos**: gr√°ficos por m√©trica, comparando modelos e par√¢metros.

### üìä Sa√≠da da pasta `Resultado/METODO_3`

* `*_predicoes.csv` ‚Üí predi√ß√µes por usu√°rio/fold.
* `*_metricas_long.csv` ‚Üí m√©tricas detalhadas por fold.
* `metricas_medias.csv` ‚Üí resumo comparativo de desempenho.
* `*_confusion_matrix.csv` e `*_confusion_matrix.png` ‚Üí matrizes de confus√£o agregadas.
* `Boxplot_Acuracia.png`, `Boxplot_Recall.png`, ‚Ä¶ ‚Üí compara√ß√µes gr√°ficas entre modelos.

## üîπ Etapa 5 - M√©todo 4: Oversampling com SMOTE (`Metodo_04.Rmd`)

O **M√©todo 4** utiliza o algoritmo **SMOTE (Synthetic Minority Over-sampling Technique)** para **aumentar a classe minorit√°ria (positiva, `1`)**, gerando **novos exemplos sint√©ticos** a partir da vizinhan√ßa existente.

### ‚öôÔ∏è Pipeline do M√©todo 4

1. **Carregamento dos dados preparados**

   * Carregamento dos arquivos da pasta `Dados_Preparados/` em listas (`TREINO`, `TESTE`).

2. **Vetoriza√ß√£o com TF-IDF**

   * Transforma√ß√£o das postagens em representa√ß√µes TF-IDF.
   * Sele√ß√£o das **250 palavras mais relevantes**.
   * Apenas colunas em comum entre treino e teste s√£o utilizadas.

3. **Aplica√ß√£o do SMOTE**

   * Ap√≥s a vetoriza√ß√£o, o algoritmo **SMOTE** √© aplicado nos conjuntos de treino.
   * Novas amostras da classe positiva s√£o criadas artificialmente.
   * O objetivo √© **reduzir o desbalanceamento** entre as classes.

4. **Treinamento e Avalia√ß√£o**

   * Modelos e par√¢metros avaliados:

     * **Random Forest (RF)** ‚Üí `mtry = {2, 126, 250}`
     * **XGBoost (XGB)** ‚Üí `nrounds = {250, 300, 350}`
     * **Regress√£o Log√≠stica Regularizada (GLMNET)** ‚Üí `lambda = {0.1, 0.5, 1}`
   * Valida√ß√£o cruzada com m√©tricas detalhadas.

5. **M√©tricas calculadas**

   * **Acur√°cia**
   * **Recall (Sensibilidade)**
   * **Especificidade**
   * **F1-score**
   * **AUC-ROC**

6. **Sa√≠das geradas**

   * **Predi√ß√µes por usu√°rio/fold**: arquivos `_predicoes.csv`.
   * **M√©tricas individuais**: `_metricas_long.csv`.
   * **Matrizes de confus√£o**: agregadas por usu√°rio (maioria dos folds).

     * Arquivos `.csv` e imagens `.png`.
   * **M√©tricas m√©dias**: `metricas_medias.csv`.
   * **Boxplots comparativos**: gr√°ficos por m√©trica, comparando modelos e par√¢metros.

### üìä Sa√≠da da pasta `Resultado/METODO_4`

* `*_predicoes.csv` ‚Üí predi√ß√µes por usu√°rio/fold.
* `*_metricas_long.csv` ‚Üí m√©tricas detalhadas por fold.
* `metricas_medias.csv` ‚Üí resumo comparativo de desempenho.
* `*_confusion_matrix.csv` e `*_confusion_matrix.png` ‚Üí matrizes de confus√£o agregadas.
* `Boxplot_Acuracia.png`, `Boxplot_Recall.png`, ‚Ä¶ ‚Üí compara√ß√µes gr√°ficas entre modelos.

## üîπ Etapa 6 - M√©todo 5: Combina√ß√£o de Undersampling + SMOTE (`Metodo_05.Rmd`)

O **M√©todo 5** combina duas estrat√©gias de balanceamento de classes:

1. **Redu√ß√£o parcial da classe majorit√°ria (Undersampling)** ‚Üí a quantidade de exemplos negativos (`0`) √© reduzida, de forma que **n0 ‚âà 2,5 √ó n1**.
2. **Aumento da classe minorit√°ria com SMOTE (Oversampling)** ‚Üí ap√≥s a redu√ß√£o, o **SMOTE** √© aplicado para gerar exemplos sint√©ticos da classe positiva (`1`).

Essa combina√ß√£o busca reduzir o vi√©s causado pelo desbalanceamento e ao mesmo tempo preservar diversidade nos exemplos de treino.

### ‚öôÔ∏è Pipeline do M√©todo 5

1. **Carregamento dos dados preparados**

   * Leitura dos arquivos de treino e teste da pasta `Dados_Preparados/`.

2. **Recombina√ß√£o inicial (Undersampling)**

   * Redu√ß√£o da classe negativa (`0`), preservando aproximadamente o dobro de exemplos em rela√ß√£o √† classe positiva.

3. **Vetoriza√ß√£o com TF-IDF**

   * Sele√ß√£o das **250 palavras mais relevantes**.
   * Apenas termos em comum entre treino e teste s√£o mantidos.

4. **Aplica√ß√£o do SMOTE**

   * Expans√£o da classe positiva (`1`) por meio da t√©cnica de vizinhos sint√©ticos (K=81).

5. **Treinamento e Avalia√ß√£o**

   * Modelos e par√¢metros testados:

     * **Random Forest (RF)** ‚Üí `mtry = {2, 126, 250}`
     * **XGBoost (XGB)** ‚Üí `nrounds = {250, 300, 350}`
     * **GLMNET (Regress√£o Log√≠stica Regularizada)** ‚Üí `lambda = {0.1, 0.5, 1}`
   * Avalia√ß√£o com valida√ß√£o cruzada.

6. **M√©tricas calculadas**

   * **Acur√°cia**
   * **Recall (Sensibilidade)**
   * **Especificidade**
   * **F1-score**
   * **AUC-ROC**

7. **Sa√≠das geradas**

   * Predi√ß√µes por usu√°rio/fold: `*_predicoes.csv`.
   * M√©tricas individuais por fold: `*_metricas_long.csv`.
   * Matrizes de confus√£o agregadas por usu√°rio (maioria dos folds), em `.csv` e `.png`.
   * Resumo de m√©tricas m√©dias: `metricas_medias.csv`.
   * Boxplots comparativos de modelos/par√¢metros: `Boxplot_*.png`.

### üìä Sa√≠da da pasta `Resultado/METODO_5`

* `*_predicoes.csv` ‚Üí predi√ß√µes por usu√°rio/fold.
* `*_metricas_long.csv` ‚Üí m√©tricas detalhadas por fold.
* `metricas_medias.csv` ‚Üí resumo comparativo de desempenho.
* `*_confusion_matrix.csv` e `*_confusion_matrix.png` ‚Üí matrizes de confus√£o agregadas.
* `Boxplot_Acuracia.png`, `Boxplot_Recall.png`, ‚Ä¶ ‚Üí compara√ß√µes gr√°ficas entre modelos.
